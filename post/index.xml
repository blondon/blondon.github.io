<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Ben London</title>
    <link>https://blondon.github.io/post/</link>
      <atom:link href="https://blondon.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 27 Sep 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://blondon.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://blondon.github.io/post/</link>
    </image>
    
    <item>
      <title>Four new papers at RecSys 2023 workshops</title>
      <link>https://blondon.github.io/post/recsys_2023/</link>
      <pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/recsys_2023/</guid>
      <description>&lt;p&gt;I recently presented four new papers at the &lt;a href=&#34;https://recsys.acm.org/recsys23/&#34;&gt;RecSys 2023&lt;/a&gt; workshops. They represent a continuation of my work on recommendation as off-policy evaluation and learning with logged bandit feedback.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;B. London, A. Buchholz, G. Di Benedetto, J. M. Lichtenberg, Y. Stein &amp;amp; T. Joachims. &lt;a href=&#34;https://blondon.github.io/publication/london-consequences23/&#34;&gt;Self-Normalized Off-Policy Estimators for Ranking&lt;/a&gt;. &lt;a href=&#34;https://sites.google.com/view/consequences2023&#34;&gt;CONSEQUENCES Workshop, 2023&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;J. M. Lichtenberg, A. Buchholz, G. Di Benedetto, M. Ruffini &amp;amp; B. London. &lt;a href=&#34;https://blondon.github.io/publication/lichtenberg-consequences23/&#34;&gt;Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation&lt;/a&gt;. &lt;a href=&#34;https://sites.google.com/view/consequences2023&#34;&gt;CONSEQUENCES Workshop, 2023&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;O. Jeunen &amp;amp; B. London. &lt;a href=&#34;https://blondon.github.io/publication/jeunen-consequences23/&#34;&gt;Offline Recommender System Evaluation under Unobserved Confounding&lt;/a&gt;. &lt;a href=&#34;https://sites.google.com/view/consequences2023&#34;&gt;CONSEQUENCES Workshop 2023&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;G. Di Benedetto, B. London, A. Buchholz, Y. Stein, V. Bellini, M. Jakimov, M. Ruffini &amp;amp; T. Joachims. &lt;a href=&#34;https://blondon.github.io/publication/dibenedetto-leri23/&#34;&gt;Contextual Position Bias Estimation using a Single Stochastic Logging Policy&lt;/a&gt;. &lt;a href=&#34;https://recsyspolimi.github.io/leri2023/&#34;&gt;LERI Workshop, 2023&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AC for ICLR 2024</title>
      <link>https://blondon.github.io/post/iclr_2024/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/iclr_2024/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m excited to announce that I&amp;rsquo;ve been invited to be an area chair for &lt;a href=&#34;https://iclr.cc/&#34;&gt;ICLR 2024&lt;/a&gt;. This is my first experience with ICLR reviewing, and I&amp;rsquo;m looking forward to it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WebConf 2023 Tutorial on &#39;&#39;Practical Bandits&#39;&#39;</title>
      <link>https://blondon.github.io/post/webconf23_tutorial/</link>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/webconf23_tutorial/</guid>
      <description>&lt;p&gt;I recently had the pleasure of collaborating with Bram van den Akker, Olivier Jeunen, Ying Li, Zahra Nazari and Devesh Parekh on a tutorial called &amp;lsquo;&amp;lsquo;Practical Bandits: An Industry Perspective,&amp;quot; which Bram and Olivier presented at &lt;a href=&#34;https://archives.iw3c2.org/www2023&#34;&gt;The Web Conference 2023&lt;/a&gt;. You can view the recording &lt;a href=&#34;https://youtu.be/lHva_kgRqq4&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New paper accepted at AISTATS 2023</title>
      <link>https://blondon.github.io/post/bopl_aistats23/</link>
      <pubDate>Fri, 20 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/bopl_aistats23/</guid>
      <description>&lt;p&gt;My recent paper on boosting for off-policy learning has been accepted at &lt;a href=&#34;https://aistats.org/aistats2023&#34;&gt;AI &amp;amp; Statistics (AISTATS) 2023&lt;/a&gt;. This work is a collaboration with Levi Lu (Amazon Music), Ted Sandler (Groundlight.ai) and Thorsten Joachims (Cornell / Amazon Music). Camera-ready coming soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two new papers at CONSEQUENCES&#43;REVEAL 2022</title>
      <link>https://blondon.github.io/post/consequences_reveal_22/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/consequences_reveal_22/</guid>
      <description>&lt;p&gt;I will be sharing two new papers &amp;ndash; representing some of the work I&amp;rsquo;ve been doing for Amazon Music &amp;ndash; at the &lt;a href=&#34;https://sites.google.com/view/consequences2022&#34;&gt;CONSEQUENCES+REVEAL Workshop&lt;/a&gt;, which is part of the &lt;a href=&#34;https://recsys.acm.org/recsys22/&#34;&gt;RecSys 2022 conference&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first paper, &amp;ldquo;&lt;a href=&#34;https://blondon.github.io/publication/london-reveal22/&#34;&gt;Control Variate Diagnostics for Detecting Problems in Logged Bandit Feedback&lt;/a&gt;,&amp;rdquo; deals with an important, practical problem in off-policy evaluation and learning that has not received much attention in the literature. When using logged bandit feedback (such as data from a recommender system) for offline evaluation, it is important that the data collection policy (a.k.a. &lt;em&gt;logging policy&lt;/em&gt; or &lt;em&gt;behavioral policy&lt;/em&gt;) is sufficiently randomized, and that the logs accurately reflect the &lt;em&gt;propensities&lt;/em&gt; (i.e., probabilities) of the selected actions. These conditions allow for unbiased evaluation of a new policy; when they fail, reward (i.e., utility) estimates may be biased. We therefore need diagnostics to test whether the conditions are met. Toward this goal, we propose diagnostics based on &lt;em&gt;control variates&lt;/em&gt; &amp;ndash; statistics with known expectations. Framed as a hypothesis test, we evaluate whether it is statistically plausible that the observed data come from a &amp;ldquo;good&amp;rdquo; data distribution. We analyze the diagnostics&amp;rsquo; false positive and false negative rates, and conduct experiments on synthetic data to empirically validate their effectiveness. I will be giving a talk for this paper on Thursday, 9/22.&lt;/p&gt;
&lt;p&gt;The second paper, &amp;ldquo;&lt;a href=&#34;https://blondon.github.io/publication/buchholz-consequences22/&#34;&gt;Off-Policy Evaluation for Learning-to-Rank via Interpolating the Item-Position Model and the Position-Based Model&lt;/a&gt;,&amp;rdquo; deals with off-policy evaluation of ranking policies. When evaluating ranking policies, one must assume a model of user interaction. Two popular choices are the &lt;em&gt;position-based model&lt;/em&gt; (PBM) and the &lt;em&gt;item-position model&lt;/em&gt; (IPM). The PBM yields an estimator that typically has low variance, but requires a position bias curve that, when estimated inaccurately, can cause high bias. Meanwhile, the IPM estimator does not require a position bias curve and, under reasonable assumptions, is unbiased &amp;ndash; however, at the expense of larger variance. To get the &amp;ldquo;best of both worlds,&amp;rdquo; we propose a new estimator, INTERPOL, that interpolates between the two models. We show that this estimator is unbiased whenever the PBM assumptions hold, and our experiments on synthetic data corroborate that INTERPOL can achieve lower estimation error than either the PBM or IPM for a properly chosen interpolation parameter. My collaborator, Alexander Buchholz, will be giving a talk for this paper on Friday, 9/23.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AC for NeurIPS 2021</title>
      <link>https://blondon.github.io/post/neurips_2021/</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/neurips_2021/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m excited to announce that I will serve as an area chair for &lt;a href=&#34;https://neurips.cc/Conferences/2021&#34;&gt;NeurIPS 2021&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeurIPS 2020</title>
      <link>https://blondon.github.io/post/neurips_2020/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://blondon.github.io/post/neurips_2020/</guid>
      <description>&lt;p&gt;I will serve as an area chair for &lt;a href=&#34;https://neurips.cc/Conferences/2020&#34;&gt;NeurIPS 2020&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ICML &amp; IJCAI 2020 </title>
      <link>https://blondon.github.io/post/icml_ijcai_2020/</link>
      <pubDate>Fri, 17 Jan 2020 12:59:45 -0800</pubDate>
      <guid>https://blondon.github.io/post/icml_ijcai_2020/</guid>
      <description>&lt;p&gt;I will serve as an area chair for &lt;a href=&#34;https://icml.cc/Conferences/2020&#34;&gt;ICML 2020&lt;/a&gt; and a Sr. PC member for &lt;a href=&#34;https://ijcai20.org/&#34;&gt;IJCAI 2020&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeurIPS Workshop: ML with Guarantees</title>
      <link>https://blondon.github.io/post/mlwg_workshop/</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 -0800</pubDate>
      <guid>https://blondon.github.io/post/mlwg_workshop/</guid>
      <description>&lt;p&gt;I am co-organizing the NeurIPS 2019 &lt;a href=&#34;https://sites.google.com/view/mlwithguarantees&#34;&gt;Workshop on Machine Learning with Guarantees&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
