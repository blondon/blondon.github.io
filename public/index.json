[{"authors":["admin"],"categories":null,"content":"I am a Sr. Scientist at Amazon Music. Broadly speaking, I research machine learning theory and algorithms, using theoretical analysis to inform the design of new ML algorithms.\nI earned my Ph.D. in 2015 at University of Maryland, where I was advised by Lise Getoor and worked closely with Ben Taskar and Bert Huang. My dissertation studied generalization in structured learning, and its relationship to the algorithmic stability of collective inference. I have also worked on: generalization guarantees for randomized learning (such as stochastic gradient methods); recommendation/personalization systems; contextual multi-armed bandits; and counterfactual learning from logged bandit feedback.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://blondon.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Sr. Scientist at Amazon Music. Broadly speaking, I research machine learning theory and algorithms, using theoretical analysis to inform the design of new ML algorithms.\nI earned my Ph.D. in 2015 at University of Maryland, where I was advised by Lise Getoor and worked closely with Ben Taskar and Bert Huang. My dissertation studied generalization in structured learning, and its relationship to the algorithmic stability of collective inference.","tags":null,"title":"Ben London","type":"authors"},{"authors":[],"categories":[],"content":"I am co-organizing the NeurIPS 2019 Workshop on Machine Learning with Guarantees.\n","date":1576310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576310400,"objectID":"ae489f29af82c4a319c0450cb3318263","permalink":"https://blondon.github.io/post/mlwg_workshop/","publishdate":"2019-12-14T00:00:00-08:00","relpermalink":"/post/mlwg_workshop/","section":"post","summary":"I am co-organizing the NeurIPS 2019 [Workshop on Machine Learning with Guarantees](https://sites.google.com/view/mlwithguarantees).","tags":[],"title":"NeurIPS Workshop: ML with Guarantees","type":"post"},{"authors":["Ben London","Ted Sandler"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3d1dcbe2c7ea2d4644adff63c801b6aa","permalink":"https://blondon.github.io/publication/london-icml-19/","publishdate":"2020-01-17T19:49:07.31286Z","relpermalink":"/publication/london-icml-19/","section":"publication","summary":"","tags":null,"title":"Bayesian Counterfactual Risk Minimization","type":"publication"},{"authors":["Ofer Meshi","Ben London","David Weller","David Sontag"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c22eb84879db3a4ea41ef1eacaf8e8cf","permalink":"https://blondon.github.io/publication/meshi-jmlr-19/","publishdate":"2020-01-17T19:49:07.311491Z","relpermalink":"/publication/meshi-jmlr-19/","section":"publication","summary":"","tags":null,"title":"Train and Test Tightness of LP Relaxations in Structured Prediction","type":"publication"},{"authors":["Ben London","Ted Sandler"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"973deac12bc35b6b69e259451a47e03e","permalink":"https://blondon.github.io/publication/london-causalml-18/","publishdate":"2020-01-17T19:49:07.313637Z","relpermalink":"/publication/london-causalml-18/","section":"publication","summary":"","tags":null,"title":"Bayesian Counterfactual Risk Minimization","type":"publication"},{"authors":["Sabina Tomkins","Steve Isley","Ben London","Lise Getoor"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"da139b5807dbc467d7ff5cc78617424a","permalink":"https://blondon.github.io/publication/tomkins-recsys-18/","publishdate":"2020-01-17T19:49:07.317985Z","relpermalink":"/publication/tomkins-recsys-18/","section":"publication","summary":"","tags":null,"title":"Sustainability at Scale: Bridging the Intention-Behavior Gap with Sustainable Recommendations","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"66a1bad963a4da29a6366724d14007a3","permalink":"https://blondon.github.io/publication/london-nips-17/","publishdate":"2020-01-17T19:49:07.314426Z","relpermalink":"/publication/london-nips-17/","section":"publication","summary":"","tags":null,"title":"A PAC-Bayesian Analysis of Randomized Learning with Application to Stochastic Gradient Descent","type":"publication"},{"authors":["Ben London","Ofer Meshi","David Weller"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"af829c4f281a48bb61dc3d0b10154c07","permalink":"https://blondon.github.io/publication/london-opt-16/","publishdate":"2020-01-17T19:49:07.315164Z","relpermalink":"/publication/london-opt-16/","section":"publication","summary":"","tags":null,"title":"Bounding the Integrality Distance of LP Relaxations for Structured Prediction","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"298f87f7bed11222d3d3413b35f2eb30","permalink":"https://blondon.github.io/publication/london-optopt-16/","publishdate":"2020-01-17T19:49:07.3164Z","relpermalink":"/publication/london-optopt-16/","section":"publication","summary":"","tags":null,"title":"Generalization Bounds for Randomized Learning with Application to Stochastic Gradient Descent","type":"publication"},{"authors":["Ben London","Alexander Schwing"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"18bf699710e0cf425d937799632e9c6c","permalink":"https://blondon.github.io/publication/london-wat-16/","publishdate":"2020-01-17T19:49:07.317256Z","relpermalink":"/publication/london-wat-16/","section":"publication","summary":"","tags":null,"title":"Generative Adversarial Structured Networks","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"40bbd1d4b5aa559634b08d1ffad9bc3c","permalink":"https://blondon.github.io/publication/london-jmlr-16/","publishdate":"2020-01-17T19:49:07.318727Z","relpermalink":"/publication/london-jmlr-16/","section":"publication","summary":"Structured prediction models have been found to learn effectively from a few large examples\u0026nbsp;â€” sometimes even just one. Despite empirical evidence, canonical learning theory cannot guarantee generalization in this setting because the error bounds decrease as a function of the number of examples. We therefore propose new PAC-Bayesian generalization bounds for structured prediction that decrease as a function of both the number of examples and the size of each example. Our analysis hinges on the stability of joint inference and the smoothness of the data distribution. We apply our bounds to several common learning scenarios, including max-margin and soft-max training of Markov random fields. Under certain conditions, the resulting error bounds can be far more optimistic than previous results and can even guarantee generalization from a single large example.\n","tags":["PAC-Bayes","generalization bounds","learning theory","structured prediction"],"title":"Stability and Generalization in Structured Prediction","type":"publication"},{"authors":["Jay Pujara","Ben London","Lise Getoor"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"38f1a94e36d9430f277dc30f58b3f5d4","permalink":"https://blondon.github.io/publication/pujara-uai-15/","publishdate":"2020-01-17T19:49:07.321055Z","relpermalink":"/publication/pujara-uai-15/","section":"publication","summary":"Updating inference in response to new evidence is a fundamental challenge in artificial intelligence. Many real problems require large probabilistic graphical models, containing millions of interdependent variables. For such large models, jointly updating the most likely (i.e., MAP) configuration of the variables each time new evidence is encountered can be infeasible, even if inference is tractable. In this paper, we introduce budgeted online collective inference, in which the MAP configuration of a graphical model is updated efficiently by revising the assignments to a subset of the variables while holding others fixed. The goal is to selectively update certain variables without sacrificing quality with respect to full inference. To formalize the consequences of partially updating inference, we introduce the concept of inference regret. We derive inference regret bounds for a class of graphical models with strongly-convex free energies. These theoretical insights, combined with a thorough analysis of the optimization solver, motivate new approximate methods for efficiently updating the variable assignments under a budget constraint. In experiments, we demonstrate that our algorithms can reduce inference time by 65% with accuracy comparable to full inference.\n","tags":null,"title":"Budgeted Online Collective Inference","type":"publication"},{"authors":["Galileo Mark Namata","Ben London","Lise Getoor"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"373d4ce02a8acd255716495977cb2623","permalink":"https://blondon.github.io/publication/namata-tkdd-15/","publishdate":"2020-01-17T19:49:07.321935Z","relpermalink":"/publication/namata-tkdd-15/","section":"publication","summary":"","tags":null,"title":"Collective Graph Identification","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"67d4b739591d52a9346e7cc235a49ae2","permalink":"https://blondon.github.io/publication/london-thesis-15/","publishdate":"2020-01-17T19:49:07.324847Z","relpermalink":"/publication/london-thesis-15/","section":"publication","summary":"","tags":null,"title":"On the Stability of Structured Prediction","type":"publication"},{"authors":["Jay Pujara","Ben London","Lise Getoor","William Cohen"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"fb1c719f194132283cb9131b530022f3","permalink":"https://blondon.github.io/publication/pujara-starai-15/","publishdate":"2020-01-17T19:49:07.323693Z","relpermalink":"/publication/pujara-starai-15/","section":"publication","summary":"","tags":null,"title":"Online Inference for Knowledge Graph Construction.","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"ed53a50c2aae9df638c7825faafae614","permalink":"https://blondon.github.io/publication/london-icml-15/","publishdate":"2020-01-17T19:49:07.319877Z","relpermalink":"/publication/london-icml-15/","section":"publication","summary":"","tags":null,"title":"The Benefits of Learning with Strongly Convex Approximate Inference","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"89d816372167f9e74bdba7c1e57597b8","permalink":"https://blondon.github.io/publication/london-nips-14-ws/","publishdate":"2020-01-17T19:49:07.327965Z","relpermalink":"/publication/london-nips-14-ws/","section":"publication","summary":"","tags":null,"title":"On the Strong Convexity of Variational Inference","type":"publication"},{"authors":["Ben London","Bert Huang","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"a298b85e7b74b4033a34c8cb23cee91b","permalink":"https://blondon.github.io/publication/london-aistats-14/","publishdate":"2020-01-17T19:49:07.326705Z","relpermalink":"/publication/london-aistats-14/","section":"publication","summary":"","tags":null,"title":"PAC-Bayesian Collective Stability","type":"publication"},{"authors":["Ben London","Sameh Khamis","Stephen H. Bach","Bert Huang","Lise Getoor","Larry Davis"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"453e1e258f5bf0856780f23b9e469667","permalink":"https://blondon.github.io/publication/london-sptli-13/","publishdate":"2020-01-17T19:49:07.330488Z","relpermalink":"/publication/london-sptli-13/","section":"publication","summary":"","tags":null,"title":"Collective Activity Detection using Hinge-loss Markov Random Fields","type":"publication"},{"authors":["Ben London","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"3d702fc54b95b9898b65c2003d9a9da6","permalink":"https://blondon.github.io/publication/london-book-13/","publishdate":"2020-01-17T19:49:07.332134Z","relpermalink":"/publication/london-book-13/","section":"publication","summary":"","tags":null,"title":"Collective Classification of Network Data","type":"publication"},{"authors":["Ben London","Bert Huang","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"21ab5df08df3724cf331004af0f700b8","permalink":"https://blondon.github.io/publication/london-icml-13/","publishdate":"2020-01-17T19:49:07.333923Z","relpermalink":"/publication/london-icml-13/","section":"publication","summary":"","tags":null,"title":"Collective Stability in Structured Prediction: Generalization from One Example","type":"publication"},{"authors":["Bert Huang","Ben London","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"036d4e2e9c781de8bc98d05354fe8c5b","permalink":"https://blondon.github.io/publication/huang-slg-13/","publishdate":"2020-01-17T19:49:07.335368Z","relpermalink":"/publication/huang-slg-13/","section":"publication","summary":"","tags":null,"title":"Empirical Analysis of Collective Stability","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"75ea6b661daeb99e32cc318bf0d66445","permalink":"https://blondon.github.io/publication/london-arxiv-13-a/","publishdate":"2020-01-17T20:20:08.812064Z","relpermalink":"/publication/london-arxiv-13-a/","section":"publication","summary":"","tags":null,"title":"Graph-based Generalization Bounds for Learning Binary Relations","type":"publication"},{"authors":["Stephen H. Bach","Bert Huang","Ben London","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"9c22b366f352ee9495a5e62f0b05e621","permalink":"https://blondon.github.io/publication/bach-uai-13/","publishdate":"2020-01-17T19:49:07.338179Z","relpermalink":"/publication/bach-uai-13/","section":"publication","summary":"Graphical models for structured domains are powerful tools, but the computational complexities of combinatorial prediction spaces can force restrictions on models, or require approximate inference in order to be tractable. Instead of working in a combinatorial space, we use hinge-loss Markov random fields (HL-MRFs), an expressive class of graphical models with log-concave density functions over continuous variables, which can represent confidences in discrete predictions. This paper demonstrates that HLMRFs are general tools for fast and accurate structured prediction. We introduce the first inference algorithm that is both scalable and applicable to the full class of HL-MRFs, and show how to train HL-MRFs with several learning algorithms. Our experiments show that HL-MRFs match or surpass the predictive performance of state-of-the-art methods, including discrete models, in four application domains.\n","tags":null,"title":"Hinge-loss Markov Random Fields: Convex Inference for Structured Prediction","type":"publication"},{"authors":["Ben London","Theodoros Rekatsinas","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"0f48c93ef00b49071495e0c0784dd69a","permalink":"https://blondon.github.io/publication/london-arxiv-13-b/","publishdate":"2020-01-17T20:20:08.813198Z","relpermalink":"/publication/london-arxiv-13-b/","section":"publication","summary":"","tags":null,"title":"Multi-relational Learning Using Weighted Tensor Decomposition with Modular Loss","type":"publication"},{"authors":["Ben London","Bert Huang","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"d48878a024a9620d559360220274b5c6","permalink":"https://blondon.github.io/publication/london-nips-13-ws/","publishdate":"2020-01-17T19:49:07.34155Z","relpermalink":"/publication/london-nips-13-ws/","section":"publication","summary":"","tags":null,"title":"PAC-Bayes Generalization Bounds for Randomized Structured Prediction","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"76ea0a468eed1cbf193cc8ba42107cf7","permalink":"https://blondon.github.io/publication/london-nips-12-asalsn/","publishdate":"2020-01-17T19:49:07.342654Z","relpermalink":"/publication/london-nips-12-asalsn/","section":"publication","summary":"","tags":null,"title":"Improved Generalization Bounds for Large-scale Structured Prediction","type":"publication"},{"authors":["Ben London","Theodoros Rekatsinas","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"498eb887e88968ad7c295419fa09ee53","permalink":"https://blondon.github.io/publication/london-nips-12-spectral/","publishdate":"2020-01-17T19:49:07.343981Z","relpermalink":"/publication/london-nips-12-spectral/","section":"publication","summary":"","tags":null,"title":"Multi-relational Weighted Tensor Decomposition","type":"publication"},{"authors":["Galileo Mark Namata","Ben London","Lise Getoor","Bert Huang"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"150d2d3b4a690bc7e4e093c0e5a86e08","permalink":"https://blondon.github.io/publication/namata-mlg-12-wkshp/","publishdate":"2020-01-17T19:49:07.345202Z","relpermalink":"/publication/namata-mlg-12-wkshp/","section":"publication","summary":"","tags":null,"title":"Query-driven Active Surveying for Collective Classification","type":"publication"},{"authors":["Jay Pujara","Ben London","Lise Getoor"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"822c4f32dd30defc42651c5b3e3617b7","permalink":"https://blondon.github.io/publication/pujara-icmlws-11/","publishdate":"2020-01-17T19:49:07.346288Z","relpermalink":"/publication/pujara-icmlws-11/","section":"publication","summary":"","tags":null,"title":"Reducing Label Cost by Combining Feature Labels and Crowdsourcing","type":"publication"}]