[{"authors":["admin"],"categories":null,"content":"I am a Principal Scientist at Amazon Music. Broadly speaking, I research machine learning theory and algorithms, using theoretical analysis to inform the design of new ML algorithms.\nI earned my Ph.D. in 2015 at University of Maryland, where I was advised by Lise Getoor and worked closely with Ben Taskar and Bert Huang. My dissertation studied generalization in structured learning, and its relationship to the algorithmic stability of collective inference. I have also worked on: generalization guarantees for randomized learning (such as stochastic gradient methods); recommendation/personalization systems; contextual multi-armed bandits; and counterfactual learning from logged bandit feedback.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://blondon.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Principal Scientist at Amazon Music. Broadly speaking, I research machine learning theory and algorithms, using theoretical analysis to inform the design of new ML algorithms.\nI earned my Ph.D. in 2015 at University of Maryland, where I was advised by Lise Getoor and worked closely with Ben Taskar and Bert Huang. My dissertation studied generalization in structured learning, and its relationship to the algorithmic stability of collective inference.","tags":null,"title":"Ben London","type":"authors"},{"authors":[],"categories":[],"content":"I am honored to serve as Industry Co-chair for RecSys 2024. To my colleagues out there designing and building the next generation of recommender systems, please consider submitting your work to the Industry track. CfP coming soon.\n","date":1700179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700179200,"objectID":"85e351ec98c2443751fcd6c7d1b0d801","permalink":"https://blondon.github.io/post/recsys_2024_industry_cochair/","publishdate":"2023-11-17T00:00:00Z","relpermalink":"/post/recsys_2024_industry_cochair/","section":"post","summary":"I am honored to serve as Industry Co-chair for [RecSys 2024](https://recsys.acm.org/recsys24/).","tags":[],"title":"Industry Co-chair for RecSys 2024","type":"post"},{"authors":[],"categories":[],"content":"I recently presented four new papers at the RecSys 2023 workshops. They represent a continuation of my work on recommendation as off-policy evaluation and learning with logged bandit feedback.\nB. London, A. Buchholz, G. Di Benedetto, J. M. Lichtenberg, Y. Stein \u0026amp; T. Joachims. Self-Normalized Off-Policy Estimators for Ranking. CONSEQUENCES Workshop, 2023 J. M. Lichtenberg, A. Buchholz, G. Di Benedetto, M. Ruffini \u0026amp; B. London. Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation. CONSEQUENCES Workshop, 2023 O. Jeunen \u0026amp; B. London. Offline Recommender System Evaluation under Unobserved Confounding. CONSEQUENCES Workshop 2023 G. Di Benedetto, B. London, A. Buchholz, Y. Stein, V. Bellini, M. Jakimov, M. Ruffini \u0026amp; T. Joachims. Contextual Position Bias Estimation using a Single Stochastic Logging Policy. LERI Workshop, 2023 ","date":1695772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695772800,"objectID":"424b4795f748c03adb8f43c18c1d6769","permalink":"https://blondon.github.io/post/recsys_2023/","publishdate":"2023-09-27T00:00:00Z","relpermalink":"/post/recsys_2023/","section":"post","summary":"I recently presented four new papers at the [RecSys 2023](https://recsys.acm.org/recsys23/) workshops","tags":[],"title":"Four new papers at RecSys 2023 workshops","type":"post"},{"authors":["Giuseppe Di Benedetto","Alexander Buchholz","Ben London","Matej Jakimov","Yannik Stein","Jan Malte Lichtenberg","Vito Bellini","Matteo Ruffini"],"categories":null,"content":"","date":1695081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695081600,"objectID":"29a0ba03148ef204f05491288c7a4950","permalink":"https://blondon.github.io/publication/dibenedetto-leri23/","publishdate":"2023-09-19T00:00:00Z","relpermalink":"/publication/dibenedetto-leri23/","section":"publication","summary":" Addressing the position bias is of pivotal importance for performing unbiased off-policy training and evaluation in Learning To Rank (LTR). This requires accurate estimates of the probabilities of the users examining the slots where items are displayed, which in many applications is likely to depend on multiple factors, e.g. the screen size. This leads to a position-bias curve that is no longer constant, but depends on the context. Existing position-bias estimators are either non-contextual or require multiple deployed ranking policies. We propose a novel contextual position-bias estimator that only requires propensities logged from a single stochastic logging policy. Empirical evaluations assess the accuracy of the model in recovering the position-bias curves as well as the impact on off-policy evaluation, showing how a contextual position-bias estimator can deliver better reward estimates which are more robust to non-stationarity compared to a non-contextual one. ","tags":null,"title":"Contextual Position Bias Estimation Using a Single Stochastic Logging Policy","type":"publication"},{"authors":["Jan Malte Lichtenberg","Alexander Buchholz","Giuseppe Di Benedetto","Matteo Ruffini","Ben London"],"categories":null,"content":"","date":1695081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695081600,"objectID":"9a23a5d5c66c727c807a488ccc5556f1","permalink":"https://blondon.github.io/publication/lichtenberg-consequences23/","publishdate":"2023-09-19T00:00:00Z","relpermalink":"/publication/lichtenberg-consequences23/","section":"publication","summary":" ''Clipping'' (a.k.a. importance weight truncation) is a widely used variance-reduction technique for counterfactual off-policy estimators. Like other variance-reduction techniques, clipping reduces variance at the cost of increased bias. However, unlike other techniques, the bias introduced by clipping is always a downward bias (assuming non-negative rewards), yielding a lower bound on the true expected reward. In this work we propose a simple extension, called double clipping, which aims to compensate this downward bias and thus reduce the overall bias, while maintaining the variance reduction properties of the original estimator. ","tags":null,"title":"Double clipping: Less-biased variance reduction in off-policy evaluation","type":"publication"},{"authors":["Olivier Jeunen","Ben London"],"categories":null,"content":"","date":1695081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695081600,"objectID":"e9207616b78da448c33004504937552d","permalink":"https://blondon.github.io/publication/jeunen-consequences23/","publishdate":"2023-09-19T00:00:00Z","relpermalink":"/publication/jeunen-consequences23/","section":"publication","summary":" Off-Policy Estimation (OPE) methods allow us to learn and evaluate decision-making policies from logged data. This makes them an attractive choice for the offline evaluation of recommender systems, and several recent works have reported successful adoption of OPE methods to this end. An important assumption that makes this work, is the absence of unobserved confounders: random variables that influence both actions and rewards at data collection time. Because the data collection policy is typically under the practitioner’s control, the unconfoundedness assumption is often left implicit, and its violations are rarely dealt with in the existing literature.\nThis work aims to highlight the problems that arise when performing off-policy estimation in the presence of unobserved confounders, specifically focusing on a recommendation use-case. We focus on policy-based estimators, where the logging propensities are learned from logged data. We characterise the statistical bias that arises due to confounding, and show how existing diagnostics are unable to uncover such cases. Because the bias depends directly on the true and unobserved logging propensities, it is non-identifiable. As the unconfoundedness assumption is famously untestable, this becomes especially problematic. This paper emphasises this common, yet often overlooked issue. Through synthetic data, we empirically show how naïve propensity estimation under confounding can lead to severely biased metric estimates that are allowed to fly under the radar. We aim to cultivate an awareness among researchers and practitioners of this important problem, and touch upon potential research directions towards mitigating its effects. ","tags":null,"title":"Offline Recommender System Evaluation under Unobserved Confounding","type":"publication"},{"authors":["Ben London","Alexander Buchholz","Giuseppe Di Benedetto","Jan Malte Lichtenberg","Yannik Stein","Thorsten Joachims"],"categories":null,"content":"","date":1695081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695081600,"objectID":"3290a2fa7af66148f0244b0ed64314ad","permalink":"https://blondon.github.io/publication/london-consequences23/","publishdate":"2023-09-19T00:00:00Z","relpermalink":"/publication/london-consequences23/","section":"publication","summary":" We propose two new estimators for off-policy evaluation of ranking policies, based on the idea of self-normalization. Importantly, these estimators are parameter-free and asymptotically unbiased. Experiments with synthetic data demonstrate that our estimators can be more accurate than other importance weighting estimators, owing to their ability to control variance, while adding minimal bias. From this, we conclude that self-normalization offers an optimal balance of accuracy and practicality for off-policy ranker evaluation. ","tags":null,"title":"Self-Normalized Off-Policy Estimators for Ranking","type":"publication"},{"authors":[],"categories":[],"content":"I\u0026rsquo;m excited to announce that I\u0026rsquo;ve been invited to be an area chair for ICLR 2024. This is my first experience with ICLR reviewing, and I\u0026rsquo;m looking forward to it.\n","date":1692230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692230400,"objectID":"964323fcb09a7ada7d06f8a3dae5d091","permalink":"https://blondon.github.io/post/iclr_2024/","publishdate":"2023-08-17T00:00:00Z","relpermalink":"/post/iclr_2024/","section":"post","summary":"I will be an area chair for [ICLR 2024](https://iclr.cc/).","tags":[],"title":"AC for ICLR 2024","type":"post"},{"authors":[],"categories":[],"content":"I recently had the pleasure of collaborating with Bram van den Akker, Olivier Jeunen, Ying Li, Zahra Nazari and Devesh Parekh on a tutorial called \u0026lsquo;\u0026lsquo;Practical Bandits: An Industry Perspective,\u0026quot; which Bram and Olivier presented at The Web Conference 2023. You can view the recording here.\n","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"6a1404c41ff952689c87f718a68bd72e","permalink":"https://blondon.github.io/post/webconf23_tutorial/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/post/webconf23_tutorial/","section":"post","summary":"I helped create a tutorial on ''Practical Bandits'' at [The Web Conference 2023](https://archives.iw3c2.org/www2023)","tags":[],"title":"WebConf 2023 Tutorial on ''Practical Bandits''","type":"post"},{"authors":["Ben London","Levi Lu","Ted Sandler","Thorsten Joachims"],"categories":null,"content":"","date":1674172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674172800,"objectID":"20e7980851d0f323e226340334681df6","permalink":"https://blondon.github.io/publication/london-aistats23/","publishdate":"2023-01-20T00:00:00Z","relpermalink":"/publication/london-aistats23/","section":"publication","summary":"We propose the first boosting algorithm for off-policy learning from logged bandit feedback. Unlike existing boosting methods for supervised learning, our algorithm directly optimizes an estimate of the policy's expected reward. We analyze this algorithm and prove that the excess empirical risk decreases (possibly exponentially fast) with each round of boosting, provided a ``weak'' learning condition is satisfied by the base learner. We further show how to reduce the base learner to supervised learning, which opens up a broad range of readily available base learners with practical benefits, such as decision trees. Experiments indicate that our algorithm inherits many desirable properties of tree-based boosting algorithms (e.g., robustness to feature scaling and hyperparameter tuning), and that it can outperform off-policy learning with deep neural networks as well as methods that simply regress on the observed rewards.","tags":null,"title":"Boosted Off-Policy Learning","type":"publication"},{"authors":[],"categories":[],"content":"My recent paper on boosting for off-policy learning has been accepted at AI \u0026amp; Statistics (AISTATS) 2023. This work is a collaboration with Levi Lu (Amazon Music), Ted Sandler (Groundlight.ai) and Thorsten Joachims (Cornell / Amazon Music). Camera-ready coming soon.\n","date":1674172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674172800,"objectID":"5824f76c77d06e7a650546cb37cf114c","permalink":"https://blondon.github.io/post/bopl_aistats23/","publishdate":"2023-01-20T00:00:00Z","relpermalink":"/post/bopl_aistats23/","section":"post","summary":"My recent paper on boosting for off-policy learning has been accepted at [AI \u0026 Statistics (AISTATS) 2023](https://aistats.org/aistats2023).","tags":[],"title":"New paper accepted at AISTATS 2023","type":"post"},{"authors":["Ben London","Thorsten Joachims"],"categories":null,"content":"","date":1663718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663718400,"objectID":"c897f40f8ee7993e6fe0bf9ae3bbf6d8","permalink":"https://blondon.github.io/publication/london-reveal22/","publishdate":"2022-09-21T00:00:00Z","relpermalink":"/publication/london-reveal22/","section":"publication","summary":" We propose diagnostics, based on control variates, to detect data quality issues in logged bandit feedback data, which is of critical importance for accurate offline evaluation and training of recommendation policies. Our diagnostics can provably detect two common types of data issues: (1) when the policy that logged the data was insufficiently randomized; (2) when the logged propensity values are incorrect due to downstream filtering. We establish bounds on the false positive and false negative rates of our diagnostics, then empirically validate our approach on synthetic data. ","tags":null,"title":"Control Variate Diagnostics for Detecting Problems in Logged Bandit Feedback","type":"publication"},{"authors":["Alexander Buchholz","Ben London","Giuseppe Benedetto","Thorsten Joachims"],"categories":null,"content":"","date":1663718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663718400,"objectID":"9fecbe00507a7cfbd26bc01a98aa35c0","permalink":"https://blondon.github.io/publication/buchholz-consequences22/","publishdate":"2022-09-21T00:00:00Z","relpermalink":"/publication/buchholz-consequences22/","section":"publication","summary":" A critical need for industrial recommender systems is the ability to evaluate recommendation policies offline, before deploying them to production. Unfortunately, widely used off-policy evaluation methods either make strong assumptions about how users behave that can lead to excessive bias, or they make fewer assumptions and suffer from large variance. We tackle this problem by developing a new estimator that mitigates the problems of the two most popular off-policy estimators for rankings, namely the position-based model and the item-position model. In particular, the new estimator, called INTERPOL, addresses the bias of a potentially misspecified position-based model, while providing an adaptable bias-variance trade-off compared to the item-position model. We provide theoretical arguments as well as empirical results that highlight the performance of our novel estimation approach. ","tags":null,"title":"Off-Policy Evaluation for Learning-to-Rank via Interpolating the Item-Position Model and the Position-Based Model","type":"publication"},{"authors":[],"categories":[],"content":"I will be sharing two new papers \u0026ndash; representing some of the work I\u0026rsquo;ve been doing for Amazon Music \u0026ndash; at the CONSEQUENCES+REVEAL Workshop, which is part of the RecSys 2022 conference.\nThe first paper, \u0026ldquo;Control Variate Diagnostics for Detecting Problems in Logged Bandit Feedback,\u0026rdquo; deals with an important, practical problem in off-policy evaluation and learning that has not received much attention in the literature. When using logged bandit feedback (such as data from a recommender system) for offline evaluation, it is important that the data collection policy (a.k.a. logging policy or behavioral policy) is sufficiently randomized, and that the logs accurately reflect the propensities (i.e., probabilities) of the selected actions. These conditions allow for unbiased evaluation of a new policy; when they fail, reward (i.e., utility) estimates may be biased. We therefore need diagnostics to test whether the conditions are met. Toward this goal, we propose diagnostics based on control variates \u0026ndash; statistics with known expectations. Framed as a hypothesis test, we evaluate whether it is statistically plausible that the observed data come from a \u0026ldquo;good\u0026rdquo; data distribution. We analyze the diagnostics\u0026rsquo; false positive and false negative rates, and conduct experiments on synthetic data to empirically validate their effectiveness. I will be giving a talk for this paper on Thursday, 9/22.\nThe second paper, \u0026ldquo;Off-Policy Evaluation for Learning-to-Rank via Interpolating the Item-Position Model and the Position-Based Model,\u0026rdquo; deals with off-policy evaluation of ranking policies. When evaluating ranking policies, one must assume a model of user interaction. Two popular choices are the position-based model (PBM) and the item-position model (IPM). The PBM yields an estimator that typically has low variance, but requires a position bias curve that, when estimated inaccurately, can cause high bias. Meanwhile, the IPM estimator does not require a position bias curve and, under reasonable assumptions, is unbiased \u0026ndash; however, at the expense of larger variance. To get the \u0026ldquo;best of both worlds,\u0026rdquo; we propose a new estimator, INTERPOL, that interpolates between the two models. We show that this estimator is unbiased whenever the PBM assumptions hold, and our experiments on synthetic data corroborate that INTERPOL can achieve lower estimation error than either the PBM or IPM for a properly chosen interpolation parameter. My collaborator, Alexander Buchholz, will be giving a talk for this paper on Friday, 9/23.\n","date":1663718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663718400,"objectID":"10c6ec12575b5e179c061a96929476f0","permalink":"https://blondon.github.io/post/consequences_reveal_22/","publishdate":"2022-09-21T00:00:00Z","relpermalink":"/post/consequences_reveal_22/","section":"post","summary":"Two new papers at the [CONSEQUENCES+REVEAL Workshop](https://sites.google.com/view/consequences2022) at [RecSys 2022 conference](https://recsys.acm.org/recsys22/).","tags":[],"title":"Two new papers at CONSEQUENCES+REVEAL 2022","type":"post"},{"authors":[],"categories":[],"content":"I\u0026rsquo;m excited to announce that I will serve as an area chair for NeurIPS 2021.\n","date":1616544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616544000,"objectID":"82e6f7ffa3ae50e37de97dd3e30eb943","permalink":"https://blondon.github.io/post/neurips_2021/","publishdate":"2021-03-24T00:00:00Z","relpermalink":"/post/neurips_2021/","section":"post","summary":"I'm excited to announce that I will serve as an area chair for [NeurIPS 2021](https://neurips.cc/Conferences/2021).","tags":[],"title":"AC for NeurIPS 2021","type":"post"},{"authors":["Thorsten Joachims","Ben London","Yi Su","Adith Swaminathan","Lequn Wang"],"categories":null,"content":"","date":1615161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615161600,"objectID":"009d7953f7f89ed0d28db8d649a027ad","permalink":"https://blondon.github.io/publication/joachims-aimag21/","publishdate":"2021-03-08T00:00:00Z","relpermalink":"/publication/joachims-aimag21/","section":"publication","summary":"In recent years, a new line of research has taken an interventional view of recommender systems, where recommendations are viewed as actions that the system takes to have a desired effect. This interventional view has led to the development of counterfactual inference techniques for evaluating and optimizing recommendation policies. This article explains how these techniques enable unbiased offline evaluation and learning despite biased data, and how they can inform considerations of fairness and equity in recommender systems.","tags":null,"title":"Recommendations as Treatments","type":"publication"},{"authors":["Ben London","Thorsten Joachims"],"categories":null,"content":"","date":1607731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607731200,"objectID":"a8c90cdf04e0ee9525498407d8d70bfd","permalink":"https://blondon.github.io/publication/london-offlinerl20/","publishdate":"2020-12-12T00:00:00Z","relpermalink":"/publication/london-offlinerl20/","section":"publication","summary":" We study offline policy evaluation in a setting where the target policy can take actions that were not available when the data was logged. We analyze the bias of two popular regression-based estimators in this setting, and upper-bound their biases by a quantity we refer to as the *reward regression risk*. We show that the estimators can be asymptotically unbiased and uniformly convergent if the reward regression risk asymptotically goes to zero. We then upper-bound the reward regression risk using tools from domain adaptation. This analysis motivates using domain adaptation algorithms to train reward predictors for offline policy evaluation. It also suggests future directions for developing improved offline policy optimization algorithms. ","tags":null,"title":"Offline Policy Evaluation with New Arms","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1607731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607731200,"objectID":"8decc30bc40416d19eafdb81e79bf607","permalink":"https://blondon.github.io/publication/london-spicyfl20/","publishdate":"2020-12-12T00:00:00Z","relpermalink":"/publication/london-spicyfl20/","section":"publication","summary":" We study privacy in federated learning systems where the model is partitioned into global and local components, the latter of which are personalized for each participating client and never shared. This setting suggests a new type of privacy breach: that the server might learn a client's local model from updates to the global model. Using on-device recommendation as a motivating example, we show that this can in fact happen in various communication protocols, even when the client obscures its update messages with noise. These findings raise new questions and open problems about privacy in an emerging application of federated learning. ","tags":null,"title":"PAC-Identifiability in Federated Learning","type":"publication"},{"authors":[],"categories":[],"content":"I will serve as an area chair for NeurIPS 2020.\n","date":1584230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584230400,"objectID":"b936a4e98ca41ec7ae7c3bb287325b4f","permalink":"https://blondon.github.io/post/neurips_2020/","publishdate":"2020-03-15T00:00:00Z","relpermalink":"/post/neurips_2020/","section":"post","summary":"I will serve as an area chair for [NeurIPS 2020](https://neurips.cc/Conferences/2020).","tags":[],"title":"NeurIPS 2020","type":"post"},{"authors":[],"categories":[],"content":"I will serve as an area chair for ICML 2020 and a Sr. PC member for IJCAI 2020.\n","date":1579294785,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579294785,"objectID":"5edd4f5e6854bdda8b552df6087efea1","permalink":"https://blondon.github.io/post/icml_ijcai_2020/","publishdate":"2020-01-17T12:59:45-08:00","relpermalink":"/post/icml_ijcai_2020/","section":"post","summary":"I will serve as an area chair for [ICML 2020](https://icml.cc/Conferences/2020) and a Sr. PC member for [IJCAI 2020](https://ijcai20.org/).","tags":[],"title":"ICML \u0026 IJCAI 2020 ","type":"post"},{"authors":[],"categories":[],"content":"I am co-organizing the NeurIPS 2019 Workshop on Machine Learning with Guarantees.\n","date":1576310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576310400,"objectID":"ae489f29af82c4a319c0450cb3318263","permalink":"https://blondon.github.io/post/mlwg_workshop/","publishdate":"2019-12-14T00:00:00-08:00","relpermalink":"/post/mlwg_workshop/","section":"post","summary":"I am co-organizing the NeurIPS 2019 [Workshop on Machine Learning with Guarantees](https://sites.google.com/view/mlwithguarantees).","tags":[],"title":"NeurIPS Workshop: ML with Guarantees","type":"post"},{"authors":["Ben London","Ted Sandler"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3d1dcbe2c7ea2d4644adff63c801b6aa","permalink":"https://blondon.github.io/publication/london-icml-19/","publishdate":"2020-01-17T19:49:07.31286Z","relpermalink":"/publication/london-icml-19/","section":"publication","summary":" We present a Bayesian view of counterfactual risk minimization (CRM) for offline learning from logged bandit feedback. Using PAC-Bayesian analysis, we derive a new generalization bound for the truncated inverse propensity score estimator. We apply the bound to a class of Bayesian policies, which motivates a novel, potentially data-dependent, regularization technique for CRM. Experimental results indicate that this technique outperforms standard ${L_2}$ regularization, and that it is competitive with variance regularization while being both simpler to implement and more computationally efficient. ","tags":null,"title":"Bayesian Counterfactual Risk Minimization","type":"publication"},{"authors":["Ofer Meshi","Ben London","David Weller","David Sontag"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c22eb84879db3a4ea41ef1eacaf8e8cf","permalink":"https://blondon.github.io/publication/meshi-jmlr-19/","publishdate":"2020-01-17T19:49:07.311491Z","relpermalink":"/publication/meshi-jmlr-19/","section":"publication","summary":" Structured prediction is used in areas including computer vision and natural language processing to predict structured outputs such as segmentations or parse trees. In these settings, prediction is performed by MAP inference or, equivalently, by solving an integer linear program. Because of the complex scoring functions required to obtain accurate predictions, both learning and inference typically require the use of approximate solvers. We propose a theoretical explanation for the striking observation that approximations based on linear programming (LP) relaxations are often tight (exact) on real-world instances. In particular, we show that learning with LP relaxed inference encourages integrality of training instances, and that this training tightness generalizes to test data. ","tags":null,"title":"Train and Test Tightness of LP Relaxations in Structured Prediction","type":"publication"},{"authors":["Ben London","Ted Sandler"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"973deac12bc35b6b69e259451a47e03e","permalink":"https://blondon.github.io/publication/london-causalml-18/","publishdate":"2020-01-17T19:49:07.313637Z","relpermalink":"/publication/london-causalml-18/","section":"publication","summary":"","tags":null,"title":"Bayesian Counterfactual Risk Minimization","type":"publication"},{"authors":["Sabina Tomkins","Steve Isley","Ben London","Lise Getoor"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"da139b5807dbc467d7ff5cc78617424a","permalink":"https://blondon.github.io/publication/tomkins-recsys-18/","publishdate":"2020-01-17T19:49:07.317985Z","relpermalink":"/publication/tomkins-recsys-18/","section":"publication","summary":"","tags":null,"title":"Sustainability at Scale: Bridging the Intention-Behavior Gap with Sustainable Recommendations","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"66a1bad963a4da29a6366724d14007a3","permalink":"https://blondon.github.io/publication/london-nips-17/","publishdate":"2020-01-17T19:49:07.314426Z","relpermalink":"/publication/london-nips-17/","section":"publication","summary":" We study the generalization error of randomized learning algorithms---focusing on stochastic gradient descent (SGD)---using a novel combination of PAC-Bayes and algorithmic stability. Importantly, our generalization bounds hold for all posterior distributions on an algorithm's random hyperparameters, including distributions that depend on the training data. This inspires an adaptive sampling algorithm for SGD that optimizes the posterior at runtime. We analyze this algorithm in the context of our generalization bounds and evaluate it on a benchmark dataset. Our experiments demonstrate that adaptive sampling can reduce empirical risk faster than uniform sampling while also improving out-of-sample accuracy. **Note**: *The latest version indicates that all references to Kuzborskij \u0026 Lampert (2017) are for v2 of the manuscript, which was posted to arXiv in March, 2017. Importantly, Theorem 3 therein (a stability bound for convex losses)---which is used to prove Proposition 3 in this paper--has a different form than in the final version.* ","tags":null,"title":"A PAC-Bayesian Analysis of Randomized Learning with Application to Stochastic Gradient Descent","type":"publication"},{"authors":["Ben London","Ofer Meshi","David Weller"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"5854794f877ea81388d651f18685a1ff","permalink":"https://blondon.github.io/publication/london-optml-16/","publishdate":"2020-01-17T19:49:07.315164Z","relpermalink":"/publication/london-optml-16/","section":"publication","summary":"","tags":null,"title":"Bounding the Integrality Distance of LP Relaxations for Structured Prediction","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"298f87f7bed11222d3d3413b35f2eb30","permalink":"https://blondon.github.io/publication/london-optopt-16/","publishdate":"2020-01-17T19:49:07.3164Z","relpermalink":"/publication/london-optopt-16/","section":"publication","summary":"","tags":null,"title":"Generalization Bounds for Randomized Learning with Application to Stochastic Gradient Descent","type":"publication"},{"authors":["Ben London","Alexander Schwing"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"18bf699710e0cf425d937799632e9c6c","permalink":"https://blondon.github.io/publication/london-wat-16/","publishdate":"2020-01-17T19:49:07.317256Z","relpermalink":"/publication/london-wat-16/","section":"publication","summary":"","tags":null,"title":"Generative Adversarial Structured Networks","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"40bbd1d4b5aa559634b08d1ffad9bc3c","permalink":"https://blondon.github.io/publication/london-jmlr-16/","publishdate":"2020-01-17T19:49:07.318727Z","relpermalink":"/publication/london-jmlr-16/","section":"publication","summary":" Structured prediction models have been found to learn effectively from a few large examples---sometimes even just one. Despite empirical evidence, canonical learning theory cannot guarantee generalization in this setting because the error bounds decrease as a function of the number of examples. We therefore propose new PAC-Bayesian generalization bounds for structured prediction that decrease as a function of both the number of examples and the size of each example. Our analysis hinges on the stability of joint inference and the smoothness of the data distribution. We apply our bounds to several common learning scenarios, including max-margin and soft-max training of Markov random fields. Under certain conditions, the resulting error bounds can be far more optimistic than previous results and can even guarantee generalization from a single large example. ","tags":["PAC-Bayes","generalization bounds","learning theory","structured prediction"],"title":"Stability and Generalization in Structured Prediction","type":"publication"},{"authors":["Jay Pujara","Ben London","Lise Getoor"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"38f1a94e36d9430f277dc30f58b3f5d4","permalink":"https://blondon.github.io/publication/pujara-uai-15/","publishdate":"2020-01-17T19:49:07.321055Z","relpermalink":"/publication/pujara-uai-15/","section":"publication","summary":"Updating inference in response to new evidence is a fundamental challenge in artificial intelligence. Many real problems require large probabilistic graphical models, containing millions of interdependent variables. For such large models, jointly updating the most likely (i.e., MAP) configuration of the variables each time new evidence is encountered can be infeasible, even if inference is tractable. In this paper, we introduce budgeted online collective inference, in which the MAP configuration of a graphical model is updated efficiently by revising the assignments to a subset of the variables while holding others fixed. The goal is to selectively update certain variables without sacrificing quality with respect to full inference. To formalize the consequences of partially updating inference, we introduce the concept of inference regret. We derive inference regret bounds for a class of graphical models with strongly-convex free energies. These theoretical insights, combined with a thorough analysis of the optimization solver, motivate new approximate methods for efficiently updating the variable assignments under a budget constraint. In experiments, we demonstrate that our algorithms can reduce inference time by 65% with accuracy comparable to full inference.\n","tags":null,"title":"Budgeted Online Collective Inference","type":"publication"},{"authors":["Galileo Mark Namata","Ben London","Lise Getoor"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"373d4ce02a8acd255716495977cb2623","permalink":"https://blondon.github.io/publication/namata-tkdd-15/","publishdate":"2020-01-17T19:49:07.321935Z","relpermalink":"/publication/namata-tkdd-15/","section":"publication","summary":"","tags":null,"title":"Collective Graph Identification","type":"publication"},{"authors":["Ben London"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"67d4b739591d52a9346e7cc235a49ae2","permalink":"https://blondon.github.io/publication/london-thesis-15/","publishdate":"2020-01-17T19:49:07.324847Z","relpermalink":"/publication/london-thesis-15/","section":"publication","summary":"","tags":null,"title":"On the Stability of Structured Prediction","type":"publication"},{"authors":["Jay Pujara","Ben London","Lise Getoor","William Cohen"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"fb1c719f194132283cb9131b530022f3","permalink":"https://blondon.github.io/publication/pujara-starai-15/","publishdate":"2020-01-17T19:49:07.323693Z","relpermalink":"/publication/pujara-starai-15/","section":"publication","summary":"","tags":null,"title":"Online Inference for Knowledge Graph Construction.","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"ed53a50c2aae9df638c7825faafae614","permalink":"https://blondon.github.io/publication/london-icml-15/","publishdate":"2020-01-17T19:49:07.319877Z","relpermalink":"/publication/london-icml-15/","section":"publication","summary":"","tags":null,"title":"The Benefits of Learning with Strongly Convex Approximate Inference","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"89d816372167f9e74bdba7c1e57597b8","permalink":"https://blondon.github.io/publication/london-nips-14-ws/","publishdate":"2020-01-17T19:49:07.327965Z","relpermalink":"/publication/london-nips-14-ws/","section":"publication","summary":"","tags":null,"title":"On the Strong Convexity of Variational Inference","type":"publication"},{"authors":["Ben London","Bert Huang","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"a298b85e7b74b4033a34c8cb23cee91b","permalink":"https://blondon.github.io/publication/london-aistats-14/","publishdate":"2020-01-17T19:49:07.326705Z","relpermalink":"/publication/london-aistats-14/","section":"publication","summary":"","tags":null,"title":"PAC-Bayesian Collective Stability","type":"publication"},{"authors":["Ben London","Sameh Khamis","Stephen H. Bach","Bert Huang","Lise Getoor","Larry Davis"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"453e1e258f5bf0856780f23b9e469667","permalink":"https://blondon.github.io/publication/london-sptli-13/","publishdate":"2020-01-17T19:49:07.330488Z","relpermalink":"/publication/london-sptli-13/","section":"publication","summary":"","tags":null,"title":"Collective Activity Detection using Hinge-loss Markov Random Fields","type":"publication"},{"authors":["Ben London","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"3d702fc54b95b9898b65c2003d9a9da6","permalink":"https://blondon.github.io/publication/london-book-13/","publishdate":"2020-01-17T19:49:07.332134Z","relpermalink":"/publication/london-book-13/","section":"publication","summary":"","tags":null,"title":"Collective Classification of Network Data","type":"publication"},{"authors":["Ben London","Bert Huang","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"21ab5df08df3724cf331004af0f700b8","permalink":"https://blondon.github.io/publication/london-icml-13/","publishdate":"2020-01-17T19:49:07.333923Z","relpermalink":"/publication/london-icml-13/","section":"publication","summary":"","tags":null,"title":"Collective Stability in Structured Prediction: Generalization from One Example","type":"publication"},{"authors":["Bert Huang","Ben London","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"036d4e2e9c781de8bc98d05354fe8c5b","permalink":"https://blondon.github.io/publication/huang-slg-13/","publishdate":"2020-01-17T19:49:07.335368Z","relpermalink":"/publication/huang-slg-13/","section":"publication","summary":"","tags":null,"title":"Empirical Analysis of Collective Stability","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"75ea6b661daeb99e32cc318bf0d66445","permalink":"https://blondon.github.io/publication/london-arxiv-13-a/","publishdate":"2020-01-17T20:20:08.812064Z","relpermalink":"/publication/london-arxiv-13-a/","section":"publication","summary":"","tags":null,"title":"Graph-based Generalization Bounds for Learning Binary Relations","type":"publication"},{"authors":["Stephen H. Bach","Bert Huang","Ben London","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"9c22b366f352ee9495a5e62f0b05e621","permalink":"https://blondon.github.io/publication/bach-uai-13/","publishdate":"2020-01-17T19:49:07.338179Z","relpermalink":"/publication/bach-uai-13/","section":"publication","summary":"Graphical models for structured domains are powerful tools, but the computational complexities of combinatorial prediction spaces can force restrictions on models, or require approximate inference in order to be tractable. Instead of working in a combinatorial space, we use hinge-loss Markov random fields (HL-MRFs), an expressive class of graphical models with log-concave density functions over continuous variables, which can represent confidences in discrete predictions. This paper demonstrates that HLMRFs are general tools for fast and accurate structured prediction. We introduce the first inference algorithm that is both scalable and applicable to the full class of HL-MRFs, and show how to train HL-MRFs with several learning algorithms. Our experiments show that HL-MRFs match or surpass the predictive performance of state-of-the-art methods, including discrete models, in four application domains.\n","tags":null,"title":"Hinge-loss Markov Random Fields: Convex Inference for Structured Prediction","type":"publication"},{"authors":["Ben London","Theodoros Rekatsinas","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"0f48c93ef00b49071495e0c0784dd69a","permalink":"https://blondon.github.io/publication/london-arxiv-13-b/","publishdate":"2020-01-17T20:20:08.813198Z","relpermalink":"/publication/london-arxiv-13-b/","section":"publication","summary":"","tags":null,"title":"Multi-relational Learning Using Weighted Tensor Decomposition with Modular Loss","type":"publication"},{"authors":["Ben London","Bert Huang","Benjamin Taskar","Lise Getoor"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"d48878a024a9620d559360220274b5c6","permalink":"https://blondon.github.io/publication/london-nips-13-ws/","publishdate":"2020-01-17T19:49:07.34155Z","relpermalink":"/publication/london-nips-13-ws/","section":"publication","summary":"","tags":null,"title":"PAC-Bayes Generalization Bounds for Randomized Structured Prediction","type":"publication"},{"authors":["Ben London","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"76ea0a468eed1cbf193cc8ba42107cf7","permalink":"https://blondon.github.io/publication/london-nips-12-asalsn/","publishdate":"2020-01-17T19:49:07.342654Z","relpermalink":"/publication/london-nips-12-asalsn/","section":"publication","summary":"","tags":null,"title":"Improved Generalization Bounds for Large-scale Structured Prediction","type":"publication"},{"authors":["Ben London","Theodoros Rekatsinas","Bert Huang","Lise Getoor"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"498eb887e88968ad7c295419fa09ee53","permalink":"https://blondon.github.io/publication/london-nips-12-spectral/","publishdate":"2020-01-17T19:49:07.343981Z","relpermalink":"/publication/london-nips-12-spectral/","section":"publication","summary":"","tags":null,"title":"Multi-relational Weighted Tensor Decomposition","type":"publication"},{"authors":["Galileo Mark Namata","Ben London","Lise Getoor","Bert Huang"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"150d2d3b4a690bc7e4e093c0e5a86e08","permalink":"https://blondon.github.io/publication/namata-mlg-12-wkshp/","publishdate":"2020-01-17T19:49:07.345202Z","relpermalink":"/publication/namata-mlg-12-wkshp/","section":"publication","summary":"","tags":null,"title":"Query-driven Active Surveying for Collective Classification","type":"publication"},{"authors":["Jay Pujara","Ben London","Lise Getoor"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"822c4f32dd30defc42651c5b3e3617b7","permalink":"https://blondon.github.io/publication/pujara-icmlws-11/","publishdate":"2020-01-17T19:49:07.346288Z","relpermalink":"/publication/pujara-icmlws-11/","section":"publication","summary":"","tags":null,"title":"Reducing Label Cost by Combining Feature Labels and Crowdsourcing","type":"publication"}]